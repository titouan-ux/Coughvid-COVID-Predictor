{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "torch.manual_seed(10)\n",
    "\n",
    "\n",
    "df1 =  pd.read_csv('/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/Dataset/metadata_compiled.csv', index_col=None)\n",
    "\n",
    "#Removing NA cough_detected\n",
    "df1=df1.loc[df1['status'].notna(),]\n",
    "df1=df1.loc[df1['cough_detected'].notna(),]\n",
    "df1= df1.loc[df1['cough_detected'] > 0.8,]\n",
    "df1=df1.drop(columns=[\"Unnamed: 0\"])\n",
    "len(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert files from webm/ogm to wav format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.convert_files import convert_files_updated\n",
    "\n",
    "path = \"/coughvid_20211012/\"\n",
    "\n",
    "convert_files_updated(path, df1)\n",
    "\n",
    "print(\"Webm to wav DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising of the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import noisereduce as nr\n",
    "from scipy.io import wavfile\n",
    "from Scripts.convert_files import is_valid_wav  # Make sure this returns True only for valid PCM .wav files\n",
    "\n",
    "# Paths\n",
    "path = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/coughvid_20211012/\"\n",
    "path_denoised = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/denoised_data/\"\n",
    "\n",
    "# Loop over UUIDs\n",
    "for fn in df1['uuid']:\n",
    "    wav_file = os.path.join(path, fn + \".wav\")\n",
    "    out_file = os.path.join(path_denoised, fn + \".wav\")\n",
    "\n",
    "    # Skip if already processed\n",
    "    if os.path.exists(out_file):\n",
    "        continue\n",
    "\n",
    "    # Skip if not a valid .wav file\n",
    "    if not is_valid_wav(wav_file):\n",
    "        print(f\"Invalid .wav file skipped: {fn}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {fn}\")\n",
    "    try:\n",
    "        rate, data = wavfile.read(wav_file)\n",
    "\n",
    "        if len(data.shape) > 1:\n",
    "            nframes, nchannels = data.shape\n",
    "            reduced_data = nr.reduce_noise(y=data.T, sr=rate)\n",
    "            wavfile.write(out_file, rate, reduced_data.T)\n",
    "        else:\n",
    "            reduced_data = nr.reduce_noise(y=data, sr=rate)\n",
    "            wavfile.write(out_file, rate, reduced_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fn}: {e}\")\n",
    "\n",
    "# Remove macOS .DS_Store file if it exists in output folder\n",
    "ds_store = os.path.join(path_denoised, \".DS_Store\")\n",
    "if os.path.exists(ds_store):\n",
    "    os.remove(ds_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_ok= [fn[:-4] for fn in os.listdir(path_denoised)]\n",
    "len(uuid_ok)\n",
    "# Only keep rows where uuid is in the list of successful denoised files\n",
    "df1 = df1[df1['uuid'].isin(uuid_ok)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove silent part and create split of distinct coughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12745/12745 [56:00<00:00,  3.79it/s] \n"
     ]
    }
   ],
   "source": [
    "from unsilence import Unsilence\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_denoised = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/denoised_data/\"\n",
    "separated_audio = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/Separated_audio/\"\n",
    "\n",
    "label = pd.DataFrame(columns=[\"uuid\",\"label\",\"non_silent_name\"])\n",
    "path_label = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/label_cut_audio.csv\"\n",
    "\n",
    "counter=0\n",
    "for fn in tqdm(os.listdir(path_denoised)):\n",
    "    u = Unsilence(path_denoised + fn)\n",
    "    u.detect_silence(short_interval_threshold=0.5)\n",
    "    audio, sample_rate = librosa.load(path_denoised + fn)\n",
    "    for instant in u.get_intervals().serialize():\n",
    "        #Only keep non-silent part\n",
    "        if not instant['is_silent']:\n",
    "            #Crop from start to end\n",
    "            cropped_audio = audio[int(instant['start']*sample_rate//1-1) :int(instant['end']*sample_rate//1 +1)  ]\n",
    "            wavfile.write(separated_audio + str(counter) + \".wav\", sample_rate, cropped_audio)\n",
    "            status = df1[df1[\"uuid\"]==fn[:-4]]['status'].values[0]\n",
    "            label.loc[len(label)] = [fn[:-4], status, str(counter) + \".wav\"]\n",
    "            counter+=1\n",
    "\n",
    "label.to_csv(path_label)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate SNR to filter the unusual sound (not clear cough, voices, clipped signals...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "path_denoised = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/denoised_data/\"\n",
    "separated_audio = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/Separated_audio/\"\n",
    "\n",
    "path_label = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/label_cut_audio.csv\"\n",
    "\n",
    "df=pd.read_csv(path_label)\n",
    "\n",
    "df['snr'] = 0\n",
    "\n",
    "def estimate_snr_split(audio, sr, top_db=20):\n",
    "    \"\"\"\n",
    "    Estimate SNR by separating silent and non-silent regions of a short audio segment.\n",
    "    `top_db` controls sensitivity of silence detection.\n",
    "    \"\"\"\n",
    "    # Identify non-silent intervals\n",
    "    intervals = librosa.effects.split(audio, top_db=top_db)\n",
    "    \n",
    "    if len(intervals) == 0:\n",
    "        return float('-inf')  # Entire audio is silent\n",
    "\n",
    "    signal_mask = np.zeros_like(audio, dtype=bool)\n",
    "    for start, end in intervals:\n",
    "        signal_mask[start:end] = True\n",
    "\n",
    "    signal_energy = np.mean(audio[signal_mask] ** 2)\n",
    "    noise_energy = np.mean(audio[~signal_mask] ** 2)\n",
    "\n",
    "    if noise_energy == 0:\n",
    "        return float('inf')  # No noise detected\n",
    "\n",
    "    snr_db = 10 * np.log10(signal_energy / noise_energy)\n",
    "    return snr_db\n",
    "\n",
    "\n",
    "snrs = []\n",
    "for fn in tqdm(os.listdir(separated_audio)):\n",
    "    if fn ==\".DS_Store\":\n",
    "        continue\n",
    "    audio, sr = librosa.load(os.path.join(separated_audio, fn), sr=None)\n",
    "    #Removing empty file -> Need to change labels file as well !\n",
    "     \n",
    "    if len(audio)==0:\n",
    "        os.remove(separated_audio + fn)\n",
    "        continue\n",
    "\n",
    "    snr= estimate_snr_split(audio, sr)\n",
    "\n",
    "    if snr ==np.inf or snr == float('inf'):\n",
    "        os.remove(separated_audio + fn)\n",
    "    else: \n",
    "        snrs.append(snr)\n",
    "        df.loc[df['non_silent_name']==fn,'snr']=snr\n",
    "\n",
    "\n",
    "plt.hist(snrs, bins=50)\n",
    "plt.xlabel(\"Estimated SNR (dB)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"SNR Distribution of Segments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO RUN to remove the files from df \n",
    "\n",
    "#Remove extrema SNR\n",
    "df_filtered = df[(df['snr'] > 19) & (df['snr'] < 100)]\n",
    "\n",
    "new_path_label = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/label_cut_audio_new.csv\"\n",
    "df_filtered.to_csv(new_path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path_label = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/label_cut_audio_new.csv\"\n",
    "df_filtered=pd.read_csv(new_path_label)\n",
    "separated_audio = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/Separated_audio/\"\n",
    "\n",
    "#Remove files filtered by SNR\n",
    "file_to_remove = [fn for fn in os.listdir(separated_audio) if fn not in df_filtered['non_silent_name'].values]\n",
    "for fn in file_to_remove :\n",
    "     os.remove(separated_audio+fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Train/Test split and creation of melspectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split by UUIDs and labels\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=True, stratify=df['label'])\n",
    "\n",
    "df_train.to_csv(\"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/train_cut_label.csv\")\n",
    "\n",
    "df_test.to_csv(\"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/test_cut_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of MelSpec on the Test set (non-augmented)\n",
    "from Scripts.spec_augment import MelSpecto\n",
    "\n",
    "separated_audio = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/Separated_audio/\"\n",
    "\n",
    "labels_cut_audio_path = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/test_cut_label.csv\"\n",
    "mels_path = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/MelSpecs_test/\"\n",
    "melspec_labels_path = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/MelSpecs_labels_test.csv\"\n",
    "\n",
    "mean_signal_length = 28835\n",
    "\n",
    "MelSpecto(waves_path = separated_audio,meanSignalLength=mean_signal_length + 1 ,labels_cut_audio_path= labels_cut_audio_path, mels_path =mels_path , melspec_labels_path = melspec_labels_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12808.wav   100 / 4128\n",
      "6984.wav   200 / 4128\n",
      "813.wav   300 / 4128\n",
      "607.wav   400 / 4128\n",
      "20742.wav   500 / 4128\n",
      "15649.wav   600 / 4128\n",
      "20427.wav   700 / 4128\n",
      "20368.wav   800 / 4128\n",
      "20589.wav   900 / 4128\n",
      "12596.wav   1000 / 4128\n",
      "11958.wav   1100 / 4128\n",
      "14233.wav   1200 / 4128\n",
      "3740.wav   1300 / 4128\n",
      "11999.wav   1400 / 4128\n",
      "20877.wav   1500 / 4128\n",
      "13864.wav   1600 / 4128\n",
      "12979.wav   1700 / 4128\n",
      "4219.wav   1800 / 4128\n",
      "1572.wav   1900 / 4128\n",
      "18074.wav   2000 / 4128\n",
      "16268.wav   2100 / 4128\n",
      "2894.wav   2200 / 4128\n",
      "647.wav   2300 / 4128\n",
      "9394.wav   2400 / 4128\n",
      "13832.wav   2500 / 4128\n",
      "9717.wav   2600 / 4128\n",
      "16701.wav   2700 / 4128\n",
      "7538.wav   2800 / 4128\n",
      "17695.wav   2900 / 4128\n",
      "20644.wav   3000 / 4128\n",
      "5286.wav   3100 / 4128\n",
      "8760.wav   3200 / 4128\n",
      "3046.wav   3300 / 4128\n",
      "4678.wav   3400 / 4128\n",
      "6272.wav   3500 / 4128\n",
      "10163.wav   3600 / 4128\n",
      "21009.wav   3700 / 4128\n",
      "11413.wav   3800 / 4128\n",
      "9993.wav   3900 / 4128\n",
      "4232.wav   4000 / 4128\n",
      "18480.wav   4100 / 4128\n"
     ]
    }
   ],
   "source": [
    "#Creation of Augmented MelSpec on the Train set (augmented)\n",
    "from Scripts.pitch_shift import pitchShift\n",
    "\n",
    "metaDataPath = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/train_cut_label.csv\"\n",
    "audioDataPath = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/Separated_audio/\"\n",
    "augmentedSignals = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/Pitch_Shift_train/\"\n",
    "\n",
    "pitchShift(metaDataPath,\n",
    "           audioDataPath,\n",
    "           augmentedSignals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting: |██████████████████████████████████████████████████| 100.0% \n"
     ]
    }
   ],
   "source": [
    "#Creation of Augmented MelSpec on the Train set (augmented)\n",
    "\n",
    "from Scripts.spec_augment import SpectAugment\n",
    "\n",
    "#Mean Signal Length\n",
    "# len_signals=list()\n",
    "# \n",
    "# for f in os.listdir(wavs_signal_augmented):\n",
    "#     if f ==\".DS_Store\":\n",
    "#         continue\n",
    "#     signal, sr = librosa.load(wavs_signal_augmented + f)\n",
    "#     len_signals.append(len(signal))\n",
    "# \n",
    "# mean_signal_length = round(np.mean(len_signals))\n",
    "# print(mean_signal_length)\n",
    "# print(mean_signal_length/sr)\n",
    "# # Manually define mean_signal_length\n",
    "mean_signal_length = 28835\n",
    "\n",
    "# Filepath for augmented audio (original and pitch shifted audio): input\n",
    "wavs_signal_augmented = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/Pitch_Shift_train/\"\n",
    "files = os.listdir(wavs_signal_augmented)\n",
    "files = [f for f in files if f.endswith('.wav')]\n",
    "\n",
    "# Filepath for where to save melspectograms: output\n",
    "augmentedData = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/MelSpecs_train_augmented/\"\n",
    "\n",
    "# Filepath for where labels (0: no COVID, 1: COVID) for each melspectogram will be saved\n",
    "labels_mels_signal_augmented = \"/Users/titouan/Desktop/HDA/Term_2/2-ML/Project/MelSpecs_labels_train_augmented.csv\"\n",
    "SpectAugment(wavs_signal_augmented,\n",
    "             files,\n",
    "             20,\n",
    "             augmentedData,\n",
    "             labels_mels_signal_augmented,\n",
    "             mean_signal_length+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
