{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-08T13:07:25.416706Z",
     "iopub.status.busy": "2025-05-08T13:07:25.415925Z",
     "iopub.status.idle": "2025-05-08T13:07:25.495186Z",
     "shell.execute_reply": "2025-05-08T13:07:25.494517Z",
     "shell.execute_reply.started": "2025-05-08T13:07:25.416682Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    3097\n",
       "1    1031\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import (f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix,\n",
    "                             roc_curve, precision_recall_curve, average_precision_score, ConfusionMatrixDisplay)\n",
    "\n",
    "torch.manual_seed(10)\n",
    "\n",
    "path_img_dir_train = \"Data/MelSpecs_train\"\n",
    "df_label_train = pd.read_csv(\"Data/MelSpecs_labels_train.csv\")\n",
    "\n",
    "path_img_dir_test = \"Data/MelSpecs_test\"\n",
    "df_label_test= pd.read_csv(\"Data/MelSpecs_labels_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T13:08:27.823710Z",
     "iopub.status.busy": "2025-05-08T13:08:27.823138Z",
     "iopub.status.idle": "2025-05-08T13:08:27.989243Z",
     "shell.execute_reply": "2025-05-08T13:08:27.988461Z",
     "shell.execute_reply.started": "2025-05-08T13:08:27.823684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(train_df, val_df) = train_test_split(df_label_train, test_size=0.1, stratify=df_label_train[\"label\"], random_state=10)\n",
    "\n",
    "class MelSpectrogramDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        #self.label_dict = label_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.df.iloc[idx][\"label\"]\n",
    "        filename = self.df.iloc[idx][\"filename\"]\n",
    "\n",
    "        # Read image\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = img.astype(np.float32) / 255.0 #Normalize to [0, 1]\n",
    "        img = img.transpose(2, 0, 1)  # Convert (H, W, C) to (C, H, W)\n",
    "\n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "full_train_dataset = MelSpectrogramDataset(df_label_train, path_img_dir_train)\n",
    "train_dataset = MelSpectrogramDataset(train_df, path_img_dir_train)\n",
    "val_dataset = MelSpectrogramDataset(val_df, path_img_dir_train)\n",
    "test_dataset = MelSpectrogramDataset(df_label_test, path_img_dir_test)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "full_train_loader = DataLoader(full_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "#FREE MEMORY\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T13:03:10.148110Z",
     "iopub.status.busy": "2025-05-07T13:03:10.147577Z",
     "iopub.status.idle": "2025-05-07T13:03:10.240467Z",
     "shell.execute_reply": "2025-05-07T13:03:10.239850Z",
     "shell.execute_reply.started": "2025-05-07T13:03:10.148089Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Input shape: torch.Size([3, 199, 515])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Get one image to determine input dimensions\n",
    "sample_img, _ = train_dataset[0]  # First image and label\n",
    "input_dim = sample_img.shape  # (C, H, W)\n",
    "print(\"Input shape:\", input_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T13:05:02.538967Z",
     "iopub.status.busy": "2025-05-07T13:05:02.538206Z",
     "iopub.status.idle": "2025-05-07T13:05:07.371358Z",
     "shell.execute_reply": "2025-05-07T13:05:07.370782Z",
     "shell.execute_reply.started": "2025-05-07T13:05:02.538935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from Models.CNN import ConvNet\n",
    "\n",
    "# Hyper-parameters\n",
    "learning_rate_cnn = 0.001\n",
    "EPOCHS = 100\n",
    "\n",
    "model = ConvNet(input_dim=input_dim)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  #Take raw logits as input and apply the sigmoid + binary cross-entropy loss internally\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T13:05:25.320305Z",
     "iopub.status.busy": "2025-05-07T13:05:25.319448Z",
     "iopub.status.idle": "2025-05-07T13:18:01.199606Z",
     "shell.execute_reply": "2025-05-07T13:18:01.197889Z",
     "shell.execute_reply.started": "2025-05-07T13:05:25.320259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###### TRAINING\n",
    " ## Training our model\n",
    "model.train()\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "    # Iterate through the epochs\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Iterate through the batches our dataloader created\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # This removes the stored gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # From forward propagation\n",
    "        y_pred_logits = model(X_batch).squeeze()\n",
    "        y_pred_proba = torch.sigmoid(y_pred_logits)\n",
    "        label_predicted = (y_pred_proba >= 0.5).int()\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(y_pred_logits, y_batch.float())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        total += y_batch.size(0)\n",
    "        correct += (label_predicted == y_batch.int()).sum().item()\n",
    "\n",
    "        # Perform backwards propagation\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_accuracies.append(train_acc)\n",
    "    train_loss.append(running_loss/len(train_loader))\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()  # Set the model to evaluation mode (no gradient computation)\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_running_loss=0.0\n",
    "    with torch.no_grad():  # No gradients required for validation\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation\n",
    "            y_pred_logits = model(X_batch).squeeze()\n",
    "            y_pred_proba = torch.sigmoid(y_pred_logits)\n",
    "            val_predicted = (y_pred_proba >= 0.5).int()\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(y_pred_logits, y_batch.float())\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            val_total += y_batch.size(0)\n",
    "            val_correct += (val_predicted == y_batch.int()).sum().item()\n",
    "\n",
    "    # Validation accuracy\n",
    "    val_acc = val_correct / val_total\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_loss.append(val_running_loss/len(val_loader))\n",
    "\n",
    "    #back to train\n",
    "    model.train()\n",
    "    \n",
    "    if e%100==0 or e==50:\n",
    "      torch.save(model.state_dict(), f'/results/cnn_new_state_augmented_{e}.pth')\n",
    "\n",
    "    if e%10==0 or e==1:\n",
    "      print(f'Epoch {e+0:03}: | Loss: {running_loss/len(train_loader):.5f} | Acc: {train_acc:.3f} | Validation Accuracy: {val_acc:.3f} |  Validation Loss: {val_running_loss/len(val_loader):.5f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T13:18:05.682975Z",
     "iopub.status.busy": "2025-05-07T13:18:05.682688Z",
     "iopub.status.idle": "2025-05-07T13:18:06.325913Z",
     "shell.execute_reply": "2025-05-07T13:18:06.325151Z",
     "shell.execute_reply.started": "2025-05-07T13:18:05.682952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_train_val_accuracy(train_accuracies,val_accuracies, title='Training and Validation Accuracy', y_lims=[0, 1]):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy over epochs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_accuracies : list\n",
    "        List of training accuracies per epoch.\n",
    "    val_accuracies : list\n",
    "        List of validation accuracies per epoch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays a plot of training and validation accuracy over epochs.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy', marker='o')\n",
    "    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy', marker='s')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.ylim(y_lims[0], y_lims[1])\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/results/accuracy_augmented.png')\n",
    "\n",
    "def plot_train_val_loss(train_loss,val_loss, title='Training and Validation Loss'):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss over epochs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_loss : list\n",
    "        List of training accuracies per epoch.\n",
    "    val_loss: list\n",
    "        List of validation accuracies per epoch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays a plot of training and validation loss over epochs.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train Loss', marker='o')\n",
    "    plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss', marker='s')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/results/loss_augmented.png')\n",
    "\n",
    "plot_train_val_accuracy(train_accuracies, val_accuracies)\n",
    "plot_train_val_loss(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:37:13.170611Z",
     "iopub.status.busy": "2025-05-04T18:37:13.169953Z",
     "iopub.status.idle": "2025-05-04T18:37:30.205259Z",
     "shell.execute_reply": "2025-05-04T18:37:30.204401Z",
     "shell.execute_reply.started": "2025-05-04T18:37:13.170586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if isinstance(model, nn.DataParallel):\n",
    "    model = model.module\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Collect TEST features and labels\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(x_batch).squeeze() \n",
    "        y_pred_proba = torch.sigmoid(outputs)\n",
    "        label_predicted = (y_pred_proba >= 0.5).int()\n",
    "\n",
    "        total += y_batch.size(0)\n",
    "        correct += (label_predicted == y_batch.int()).sum().item()\n",
    "\n",
    "        all_labels.append(y_batch.int().cpu())\n",
    "        all_probs.append(y_pred_proba.cpu())\n",
    "\n",
    "# Concatenate all batches\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "all_probs = torch.cat(all_probs).numpy()\n",
    "\n",
    "# Compute metrics\n",
    "p=0.5\n",
    "precision = precision_score(all_labels,(all_probs >= p).astype(int),  average=\"binary\")\n",
    "recall = recall_score(all_labels,(all_probs >= p).astype(int), average=\"binary\")\n",
    "f1 = f1_score(all_labels,(all_probs >= p).astype(int), average=None)[1]\n",
    "auc=roc_auc_score(all_labels,(all_probs >= p).astype(int), average=None)\n",
    "\n",
    "test_accuracy=correct / total\n",
    "\n",
    "print('Test Accuracy: {:.2f} %, Precision: {:.2f} %, Recall: {:.2f} %, F1-Score: {:.2f} %, AUC: {:.2f} %'.format(\n",
    "    test_accuracy * 100, precision * 100, recall * 100, f1 * 100, auc * 100))\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # dashed diagonal\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.savefig('/kaggle/working/roc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, (all_probs >= p).astype(int))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximizing F1 score**\n",
    "\n",
    "Inspect the precision-recall curve and f1 vs threshold score, and change threshold to maximise F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pr_and_f1_curves(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Plot precision-recall curve and F1 vs threshold curve.\n",
    "    \"\"\"\n",
    "    # PR data\n",
    "    prec, rec, thresh = precision_recall_curve(y_true, y_prob)\n",
    "    prec, rec = prec[:-1], rec[:-1]\n",
    "    f1 = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
    "\n",
    "    best_idx      = np.argmax(f1)\n",
    "    best_thr      = thresh[best_idx]\n",
    "    best_f1       = f1[best_idx]\n",
    "    avg_prec      = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(11, 4.5))\n",
    "\n",
    "    # Left: PR curve\n",
    "    ax[0].plot(rec, prec, color='tab:blue', label=f'PR curve  (AP = {avg_prec:.3f})')\n",
    "    ax[0].scatter(rec[best_idx], prec[best_idx], color='red', zorder=5,\n",
    "                  label=f'Best F₁ = {best_f1:.3f}\\n@ thr = {best_thr:.2f}')\n",
    "    ax[0].set_xlabel('Recall')\n",
    "    ax[0].set_ylabel('Precision')\n",
    "    ax[0].set_title('Precision–Recall curve')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Right: F1 vs threshold\n",
    "    ax[1].plot(thresh, f1, color='tab:blue')\n",
    "    ax[1].scatter(best_thr, best_f1, color='red', zorder=5)\n",
    "    ax[1].set_xlabel('Threshold')\n",
    "    ax[1].set_ylabel('F₁ score')\n",
    "    ax[1].set_title('F₁ score vs decision threshold')\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/pr_f1.png')\n",
    "    plt.show()\n",
    "\n",
    "    return best_thr, best_f1\n",
    "\n",
    "# Plot precision-recall and F1 vs threshold plots\n",
    "best_thr, best_f1 = pr_and_f1_curves(all_labels, all_probs)\n",
    "print(f\"Optimal threshold = {best_thr:.3f}  |  Best F1 = {best_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change threshold to maximise F1 score\n",
    "final_preds = (np.array(all_probs) >= best_thr).astype(int)\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, final_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/Confusion_matrix_optimised.png')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7328236,
     "sourceId": 11676207,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7355825,
     "sourceId": 11718098,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7365472,
     "sourceId": 11732868,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
